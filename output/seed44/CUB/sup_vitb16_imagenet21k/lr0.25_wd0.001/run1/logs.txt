[05/12 19:46:00][INFO] visual_prompt:   96: Rank of current process: 0. World size: 1
[05/12 19:46:00][INFO] visual_prompt:   97: Environment info:
-------------------  -------------------------------------------------------------------------------
Python               3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0,1,2
GPU 0,1,2            NVIDIA GeForce RTX 2080 Ti
Pillow               9.0.1
-------------------  -------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[05/12 19:46:00][INFO] visual_prompt:   99: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'False', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'CUB', 'DATA.NUMBER_CLASSES', '200', 'SOLVER.BASE_LR', '0.25', 'SOLVER.WEIGHT_DECAY', '0.001', 'SEED', '44', 'MODEL.MODEL_ROOT', '/workspace/model', 'DATA.DATAPATH', '/workspace/CUB_200_2011', 'OUTPUT_DIR', '/root/nlp/vpt_skill/output/seed44'], train_type='')
[05/12 19:46:00][INFO] visual_prompt:  104: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: "/workspace/CUB_200_2011"
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[05/12 19:46:00][INFO] visual_prompt:  108: Training with config:
[05/12 19:46:00][INFO] visual_prompt:  109: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 32,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/workspace/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'tcp://:12399',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/workspace/model',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': False,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 50,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '/root/nlp/vpt_skill/output/seed44/CUB/sup_vitb16_imagenet21k/lr0.25_wd0.001/run1',
 'RUN_N_TIMES': 1,
 'SEED': 44,
 'SOLVER': {'BASE_LR': 0.25,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.001,
            'WEIGHT_DECAY_BIAS': 0}}
[05/12 19:46:00][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[05/12 19:46:00][INFO] visual_prompt:   27: Constructing CUB dataset train...
[05/12 19:46:00][INFO] visual_prompt:   70: Number of images: 5394
[05/12 19:46:00][INFO] visual_prompt:   71: Number of classes: 200
[05/12 19:46:00][INFO] visual_prompt:   73: Loading validation data...
[05/12 19:46:00][INFO] visual_prompt:   27: Constructing CUB dataset val...
[05/12 19:46:00][INFO] visual_prompt:   70: Number of images: 600
[05/12 19:46:00][INFO] visual_prompt:   71: Number of classes: 200
[05/12 19:46:00][INFO] visual_prompt:   76: Loading test data...
[05/12 19:46:00][INFO] visual_prompt:   27: Constructing CUB dataset test...
[05/12 19:46:00][INFO] visual_prompt:   70: Number of images: 5794
[05/12 19:46:00][INFO] visual_prompt:   71: Number of classes: 200
[05/12 19:46:00][INFO] visual_prompt:  103: Constructing models...
[05/12 19:46:02][INFO] visual_prompt:   53: Total Parameters: 85990856	 Gradient Parameters: 192200
[05/12 19:46:02][INFO] visual_prompt:   54: tuned percent:0.224
[05/12 19:46:03][INFO] visual_prompt:   40: Device used for model: 0
[05/12 19:46:03][INFO] visual_prompt:  106: Setting up Evalutator...
[05/12 19:46:03][INFO] visual_prompt:  108: Setting up Trainer...
[05/12 19:46:03][INFO] visual_prompt:   44: 	Setting up the optimizer...
[05/12 19:46:03][INFO] visual_prompt:  165: Training 1 / 100 epoch, with learning rate 0.0
[05/12 19:46:34][INFO] visual_prompt:  213: 	Training 100/169. train loss: 5.5873,	0.3004 s / batch. (data: 1.44e-04). ETA=1:24:06, max mem: 7.0 GB 
[05/12 19:46:55][INFO] visual_prompt:  219: Epoch 1 / 100: avg data time: 2.09e-03, avg batch time: 0.3044, average train loss: 5.4505
[05/12 19:46:58][INFO] visual_prompt:  324: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1477, average loss: 5.4576
[05/12 19:46:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 2.83	
[05/12 19:47:13][INFO] visual_prompt:  314: 	Test 100/182. loss: 5.117, 0.1481 s / batch. (data: 3.17e-05)max mem: 6.98685 GB 
[05/12 19:47:25][INFO] visual_prompt:  324: Inference (test):avg data time: 2.91e-05, avg batch time: 0.1475, average loss: 5.4584
[05/12 19:47:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.47	top5: 2.17	
[05/12 19:47:25][INFO] visual_prompt:  246: Best epoch 1: best metric: 0.008
[05/12 19:47:25][INFO] visual_prompt:  165: Training 2 / 100 epoch, with learning rate 0.025
[05/12 19:47:55][INFO] visual_prompt:  213: 	Training 100/169. train loss: 4.3414,	0.3017 s / batch. (data: 1.29e-04). ETA=1:23:37, max mem: 7.0 GB 
[05/12 19:48:16][INFO] visual_prompt:  219: Epoch 2 / 100: avg data time: 2.16e-03, avg batch time: 0.3029, average train loss: 4.4585
[05/12 19:48:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1478, average loss: 3.4001
[05/12 19:48:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 52.83	top5: 86.83	
[05/12 19:48:35][INFO] visual_prompt:  314: 	Test 100/182. loss: 2.740, 0.1484 s / batch. (data: 2.10e-05)max mem: 6.98685 GB 
[05/12 19:48:47][INFO] visual_prompt:  324: Inference (test):avg data time: 2.40e-05, avg batch time: 0.1477, average loss: 3.4171
[05/12 19:48:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 53.69	top5: 84.78	
[05/12 19:48:47][INFO] visual_prompt:  246: Best epoch 2: best metric: 0.528
[05/12 19:48:47][INFO] visual_prompt:  165: Training 3 / 100 epoch, with learning rate 0.05
[05/12 19:49:17][INFO] visual_prompt:  213: 	Training 100/169. train loss: 2.3249,	0.3014 s / batch. (data: 1.03e-04). ETA=1:22:41, max mem: 7.0 GB 
[05/12 19:49:38][INFO] visual_prompt:  219: Epoch 3 / 100: avg data time: 2.12e-03, avg batch time: 0.3031, average train loss: 2.3015
[05/12 19:49:41][INFO] visual_prompt:  324: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1480, average loss: 1.5290
[05/12 19:49:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.83	top5: 94.83	
[05/12 19:49:56][INFO] visual_prompt:  314: 	Test 100/182. loss: 1.226, 0.1485 s / batch. (data: 1.98e-05)max mem: 6.98685 GB 
[05/12 19:50:08][INFO] visual_prompt:  324: Inference (test):avg data time: 3.02e-05, avg batch time: 0.1478, average loss: 1.5366
[05/12 19:50:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.52	top5: 95.32	
[05/12 19:50:08][INFO] visual_prompt:  246: Best epoch 3: best metric: 0.728
[05/12 19:50:08][INFO] visual_prompt:  165: Training 4 / 100 epoch, with learning rate 0.075
[05/12 19:50:39][INFO] visual_prompt:  213: 	Training 100/169. train loss: 1.2584,	0.3022 s / batch. (data: 2.75e-04). ETA=1:22:03, max mem: 7.0 GB 
[05/12 19:51:00][INFO] visual_prompt:  219: Epoch 4 / 100: avg data time: 1.65e-03, avg batch time: 0.3027, average train loss: 1.2594
[05/12 19:51:03][INFO] visual_prompt:  324: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1479, average loss: 1.0533
[05/12 19:51:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.17	top5: 95.33	
[05/12 19:51:18][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.793, 0.1487 s / batch. (data: 2.07e-05)max mem: 6.98685 GB 
[05/12 19:51:30][INFO] visual_prompt:  324: Inference (test):avg data time: 3.05e-05, avg batch time: 0.1478, average loss: 1.0643
[05/12 19:51:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.04	top5: 96.24	
[05/12 19:51:30][INFO] visual_prompt:  246: Best epoch 4: best metric: 0.772
[05/12 19:51:30][INFO] visual_prompt:  165: Training 5 / 100 epoch, with learning rate 0.1
[05/12 19:52:00][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7085,	0.3016 s / batch. (data: 8.15e-05). ETA=1:21:03, max mem: 7.0 GB 
[05/12 19:52:21][INFO] visual_prompt:  219: Epoch 5 / 100: avg data time: 1.68e-03, avg batch time: 0.3028, average train loss: 0.9549
[05/12 19:52:24][INFO] visual_prompt:  324: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1478, average loss: 0.9038
[05/12 19:52:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 97.67	
[05/12 19:52:40][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.585, 0.1485 s / batch. (data: 1.93e-05)max mem: 6.98685 GB 
[05/12 19:52:52][INFO] visual_prompt:  324: Inference (test):avg data time: 2.97e-05, avg batch time: 0.1478, average loss: 0.9089
[05/12 19:52:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.96	top5: 97.01	
[05/12 19:52:52][INFO] visual_prompt:  246: Best epoch 5: best metric: 0.780
[05/12 19:52:52][INFO] visual_prompt:  165: Training 6 / 100 epoch, with learning rate 0.125
[05/12 19:53:22][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7357,	0.3019 s / batch. (data: 1.15e-04). ETA=1:20:17, max mem: 7.0 GB 
[05/12 19:53:43][INFO] visual_prompt:  219: Epoch 6 / 100: avg data time: 2.19e-03, avg batch time: 0.3032, average train loss: 0.8371
[05/12 19:53:46][INFO] visual_prompt:  324: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1479, average loss: 0.8485
[05/12 19:53:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.83	top5: 97.17	
[05/12 19:54:01][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.780, 0.1487 s / batch. (data: 1.11e-04)max mem: 6.98685 GB 
[05/12 19:54:13][INFO] visual_prompt:  324: Inference (test):avg data time: 3.19e-05, avg batch time: 0.1478, average loss: 0.8556
[05/12 19:54:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.51	top5: 97.32	
[05/12 19:54:13][INFO] visual_prompt:  246: Best epoch 6: best metric: 0.788
[05/12 19:54:13][INFO] visual_prompt:  165: Training 7 / 100 epoch, with learning rate 0.15
[05/12 19:54:44][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.8453,	0.3014 s / batch. (data: 8.34e-05). ETA=1:19:18, max mem: 7.0 GB 
[05/12 19:55:05][INFO] visual_prompt:  219: Epoch 7 / 100: avg data time: 2.11e-03, avg batch time: 0.3032, average train loss: 0.7772
[05/12 19:55:08][INFO] visual_prompt:  324: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1481, average loss: 0.8071
[05/12 19:55:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.50	top5: 98.50	
[05/12 19:55:23][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.558, 0.1484 s / batch. (data: 3.67e-05)max mem: 6.98685 GB 
[05/12 19:55:35][INFO] visual_prompt:  324: Inference (test):avg data time: 3.46e-05, avg batch time: 0.1478, average loss: 0.8155
[05/12 19:55:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.72	top5: 97.39	
[05/12 19:55:35][INFO] visual_prompt:  246: Best epoch 7: best metric: 0.795
[05/12 19:55:35][INFO] visual_prompt:  165: Training 8 / 100 epoch, with learning rate 0.175
[05/12 19:56:06][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6411,	0.3019 s / batch. (data: 1.28e-04). ETA=1:18:35, max mem: 7.0 GB 
[05/12 19:56:26][INFO] visual_prompt:  219: Epoch 8 / 100: avg data time: 2.17e-03, avg batch time: 0.3033, average train loss: 0.7502
[05/12 19:56:30][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1480, average loss: 0.8154
[05/12 19:56:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 98.17	
[05/12 19:56:45][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.868, 0.1484 s / batch. (data: 3.67e-05)max mem: 6.98685 GB 
[05/12 19:56:57][INFO] visual_prompt:  324: Inference (test):avg data time: 3.08e-05, avg batch time: 0.1478, average loss: 0.8173
[05/12 19:56:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.39	top5: 97.29	
[05/12 19:56:57][INFO] visual_prompt:  246: Best epoch 8: best metric: 0.800
[05/12 19:56:57][INFO] visual_prompt:  165: Training 9 / 100 epoch, with learning rate 0.2
[05/12 19:57:27][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6795,	0.3017 s / batch. (data: 8.46e-05). ETA=1:17:41, max mem: 7.0 GB 
[05/12 19:57:48][INFO] visual_prompt:  219: Epoch 9 / 100: avg data time: 2.32e-03, avg batch time: 0.3034, average train loss: 0.7115
[05/12 19:57:51][INFO] visual_prompt:  324: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1481, average loss: 0.7972
[05/12 19:57:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 97.50	
[05/12 19:58:06][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.365, 0.1483 s / batch. (data: 1.96e-05)max mem: 6.98685 GB 
[05/12 19:58:19][INFO] visual_prompt:  324: Inference (test):avg data time: 2.92e-05, avg batch time: 0.1478, average loss: 0.8025
[05/12 19:58:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.84	top5: 97.12	
[05/12 19:58:19][INFO] visual_prompt:  246: Best epoch 9: best metric: 0.812
[05/12 19:58:19][INFO] visual_prompt:  165: Training 10 / 100 epoch, with learning rate 0.225
[05/12 19:58:49][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6941,	0.3020 s / batch. (data: 8.15e-05). ETA=1:16:53, max mem: 7.0 GB 
[05/12 19:59:10][INFO] visual_prompt:  219: Epoch 10 / 100: avg data time: 1.69e-03, avg batch time: 0.3028, average train loss: 0.7249
[05/12 19:59:13][INFO] visual_prompt:  324: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1479, average loss: 0.7767
[05/12 19:59:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 97.67	
[05/12 19:59:28][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.529, 0.1485 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 19:59:40][INFO] visual_prompt:  324: Inference (test):avg data time: 3.07e-05, avg batch time: 0.1478, average loss: 0.8020
[05/12 19:59:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.58	top5: 97.51	
[05/12 19:59:40][INFO] visual_prompt:  165: Training 11 / 100 epoch, with learning rate 0.25
[05/12 20:00:11][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7381,	0.3016 s / batch. (data: 8.03e-05). ETA=1:15:57, max mem: 7.0 GB 
[05/12 20:00:31][INFO] visual_prompt:  219: Epoch 11 / 100: avg data time: 1.55e-03, avg batch time: 0.3026, average train loss: 0.7113
[05/12 20:00:35][INFO] visual_prompt:  324: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1478, average loss: 0.8042
[05/12 20:00:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 97.33	
[05/12 20:00:50][INFO] visual_prompt:  314: 	Test 100/182. loss: 1.258, 0.1485 s / batch. (data: 2.15e-05)max mem: 6.98685 GB 
[05/12 20:01:02][INFO] visual_prompt:  324: Inference (test):avg data time: 2.92e-05, avg batch time: 0.1478, average loss: 0.8201
[05/12 20:01:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.10	top5: 97.19	
[05/12 20:01:02][INFO] visual_prompt:  165: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[05/12 20:01:32][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6876,	0.3019 s / batch. (data: 8.30e-05). ETA=1:15:11, max mem: 7.0 GB 
[05/12 20:01:53][INFO] visual_prompt:  219: Epoch 12 / 100: avg data time: 2.18e-03, avg batch time: 0.3033, average train loss: 0.7099
[05/12 20:01:56][INFO] visual_prompt:  324: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1479, average loss: 0.7816
[05/12 20:01:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 97.17	
[05/12 20:02:11][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.414, 0.1487 s / batch. (data: 3.77e-05)max mem: 6.98685 GB 
[05/12 20:02:23][INFO] visual_prompt:  324: Inference (test):avg data time: 2.73e-05, avg batch time: 0.1478, average loss: 0.7858
[05/12 20:02:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.08	top5: 97.26	
[05/12 20:02:24][INFO] visual_prompt:  165: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[05/12 20:02:54][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5123,	0.3020 s / batch. (data: 1.07e-04). ETA=1:14:21, max mem: 7.0 GB 
[05/12 20:03:15][INFO] visual_prompt:  219: Epoch 13 / 100: avg data time: 1.93e-03, avg batch time: 0.3030, average train loss: 0.7023
[05/12 20:03:18][INFO] visual_prompt:  324: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1479, average loss: 0.7788
[05/12 20:03:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 96.33	
[05/12 20:03:33][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.362, 0.1485 s / batch. (data: 3.55e-05)max mem: 6.98685 GB 
[05/12 20:03:45][INFO] visual_prompt:  324: Inference (test):avg data time: 4.06e-05, avg batch time: 0.1478, average loss: 0.7811
[05/12 20:03:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.36	top5: 97.46	
[05/12 20:03:45][INFO] visual_prompt:  165: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[05/12 20:04:16][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.9553,	0.3018 s / batch. (data: 1.13e-04). ETA=1:13:27, max mem: 7.0 GB 
[05/12 20:04:37][INFO] visual_prompt:  219: Epoch 14 / 100: avg data time: 2.23e-03, avg batch time: 0.3032, average train loss: 0.6957
[05/12 20:04:40][INFO] visual_prompt:  324: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1479, average loss: 0.8057
[05/12 20:04:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 96.83	
[05/12 20:04:55][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.444, 0.1486 s / batch. (data: 3.55e-05)max mem: 6.98685 GB 
[05/12 20:05:07][INFO] visual_prompt:  324: Inference (test):avg data time: 3.19e-05, avg batch time: 0.1478, average loss: 0.8175
[05/12 20:05:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.63	top5: 97.12	
[05/12 20:05:07][INFO] visual_prompt:  165: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[05/12 20:05:37][INFO] visual_prompt:  213: 	Training 100/169. train loss: 1.0002,	0.3018 s / batch. (data: 1.28e-04). ETA=1:12:36, max mem: 7.0 GB 
[05/12 20:05:58][INFO] visual_prompt:  219: Epoch 15 / 100: avg data time: 1.65e-03, avg batch time: 0.3028, average train loss: 0.6984
[05/12 20:06:01][INFO] visual_prompt:  324: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1481, average loss: 0.7773
[05/12 20:06:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 98.50	
[05/12 20:06:17][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.587, 0.1488 s / batch. (data: 3.58e-05)max mem: 6.98685 GB 
[05/12 20:06:29][INFO] visual_prompt:  324: Inference (test):avg data time: 2.98e-05, avg batch time: 0.1478, average loss: 0.8095
[05/12 20:06:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.89	top5: 97.17	
[05/12 20:06:29][INFO] visual_prompt:  165: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[05/12 20:06:59][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7384,	0.3024 s / batch. (data: 9.70e-05). ETA=1:11:53, max mem: 7.0 GB 
[05/12 20:07:20][INFO] visual_prompt:  219: Epoch 16 / 100: avg data time: 2.17e-03, avg batch time: 0.3033, average train loss: 0.6934
[05/12 20:07:23][INFO] visual_prompt:  324: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1479, average loss: 0.7838
[05/12 20:07:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 97.00	
[05/12 20:07:38][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.329, 0.1485 s / batch. (data: 1.91e-05)max mem: 6.98685 GB 
[05/12 20:07:50][INFO] visual_prompt:  324: Inference (test):avg data time: 2.96e-05, avg batch time: 0.1478, average loss: 0.7960
[05/12 20:07:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.98	top5: 97.50	
[05/12 20:07:50][INFO] visual_prompt:  165: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[05/12 20:08:21][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.9387,	0.3016 s / batch. (data: 1.86e-04). ETA=1:10:51, max mem: 7.0 GB 
[05/12 20:08:42][INFO] visual_prompt:  219: Epoch 17 / 100: avg data time: 1.61e-03, avg batch time: 0.3026, average train loss: 0.6970
[05/12 20:08:45][INFO] visual_prompt:  324: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1482, average loss: 0.7927
[05/12 20:08:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 97.17	
[05/12 20:09:00][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.312, 0.1484 s / batch. (data: 1.91e-05)max mem: 6.98685 GB 
[05/12 20:09:12][INFO] visual_prompt:  324: Inference (test):avg data time: 3.17e-05, avg batch time: 0.1478, average loss: 0.7999
[05/12 20:09:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.22	top5: 97.36	
[05/12 20:09:12][INFO] visual_prompt:  165: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[05/12 20:09:42][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6977,	0.3019 s / batch. (data: 1.93e-04). ETA=1:10:04, max mem: 7.0 GB 
[05/12 20:10:03][INFO] visual_prompt:  219: Epoch 18 / 100: avg data time: 1.71e-03, avg batch time: 0.3028, average train loss: 0.6834
[05/12 20:10:06][INFO] visual_prompt:  324: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1480, average loss: 0.7637
[05/12 20:10:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 97.67	
[05/12 20:10:21][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.388, 0.1485 s / batch. (data: 3.67e-05)max mem: 6.98685 GB 
[05/12 20:10:34][INFO] visual_prompt:  324: Inference (test):avg data time: 3.22e-05, avg batch time: 0.1478, average loss: 0.7760
[05/12 20:10:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.19	top5: 97.32	
[05/12 20:10:34][INFO] visual_prompt:  165: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[05/12 20:11:04][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.9100,	0.3022 s / batch. (data: 8.11e-05). ETA=1:09:17, max mem: 7.0 GB 
[05/12 20:11:25][INFO] visual_prompt:  219: Epoch 19 / 100: avg data time: 2.04e-03, avg batch time: 0.3031, average train loss: 0.6905
[05/12 20:11:28][INFO] visual_prompt:  324: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1480, average loss: 0.7655
[05/12 20:11:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.50	top5: 98.33	
[05/12 20:11:43][INFO] visual_prompt:  314: 	Test 100/182. loss: 1.216, 0.1484 s / batch. (data: 1.98e-05)max mem: 6.98685 GB 
[05/12 20:11:55][INFO] visual_prompt:  324: Inference (test):avg data time: 2.94e-05, avg batch time: 0.1478, average loss: 0.7798
[05/12 20:11:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.12	top5: 97.65	
[05/12 20:11:55][INFO] visual_prompt:  246: Best epoch 19: best metric: 0.815
[05/12 20:11:55][INFO] visual_prompt:  165: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[05/12 20:12:26][INFO] visual_prompt:  213: 	Training 100/169. train loss: 1.0667,	0.3021 s / batch. (data: 7.84e-05). ETA=1:08:25, max mem: 7.0 GB 
[05/12 20:12:47][INFO] visual_prompt:  219: Epoch 20 / 100: avg data time: 1.61e-03, avg batch time: 0.3027, average train loss: 0.6871
[05/12 20:12:50][INFO] visual_prompt:  324: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1479, average loss: 0.7880
[05/12 20:12:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 98.00	
[05/12 20:13:05][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.637, 0.1484 s / batch. (data: 3.79e-05)max mem: 6.98685 GB 
[05/12 20:13:17][INFO] visual_prompt:  324: Inference (test):avg data time: 2.70e-05, avg batch time: 0.1478, average loss: 0.7972
[05/12 20:13:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.36	top5: 97.03	
[05/12 20:13:17][INFO] visual_prompt:  165: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[05/12 20:13:47][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5110,	0.3016 s / batch. (data: 7.84e-05). ETA=1:07:27, max mem: 7.0 GB 
[05/12 20:14:08][INFO] visual_prompt:  219: Epoch 21 / 100: avg data time: 1.87e-03, avg batch time: 0.3029, average train loss: 0.6850
[05/12 20:14:11][INFO] visual_prompt:  324: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1478, average loss: 0.7926
[05/12 20:14:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 97.33	
[05/12 20:14:26][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.650, 0.1488 s / batch. (data: 3.77e-05)max mem: 6.98685 GB 
[05/12 20:14:38][INFO] visual_prompt:  324: Inference (test):avg data time: 2.81e-05, avg batch time: 0.1478, average loss: 0.7986
[05/12 20:14:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.22	top5: 97.45	
[05/12 20:14:39][INFO] visual_prompt:  165: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[05/12 20:15:09][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.8108,	0.3015 s / batch. (data: 1.04e-04). ETA=1:06:34, max mem: 7.0 GB 
[05/12 20:15:30][INFO] visual_prompt:  219: Epoch 22 / 100: avg data time: 1.67e-03, avg batch time: 0.3026, average train loss: 0.6762
[05/12 20:15:33][INFO] visual_prompt:  324: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1481, average loss: 0.7713
[05/12 20:15:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 97.33	
[05/12 20:15:48][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.518, 0.1484 s / batch. (data: 1.88e-05)max mem: 6.98685 GB 
[05/12 20:16:00][INFO] visual_prompt:  324: Inference (test):avg data time: 3.51e-05, avg batch time: 0.1478, average loss: 0.7591
[05/12 20:16:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.36	top5: 97.83	
[05/12 20:16:00][INFO] visual_prompt:  165: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[05/12 20:16:30][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7165,	0.3012 s / batch. (data: 8.20e-05). ETA=1:05:40, max mem: 7.0 GB 
[05/12 20:16:51][INFO] visual_prompt:  219: Epoch 23 / 100: avg data time: 1.65e-03, avg batch time: 0.3026, average train loss: 0.6869
[05/12 20:16:54][INFO] visual_prompt:  324: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1479, average loss: 0.7651
[05/12 20:16:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 97.83	
[05/12 20:17:10][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.466, 0.1484 s / batch. (data: 3.67e-05)max mem: 6.98685 GB 
[05/12 20:17:22][INFO] visual_prompt:  324: Inference (test):avg data time: 2.95e-05, avg batch time: 0.1477, average loss: 0.7854
[05/12 20:17:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.60	top5: 97.48	
[05/12 20:17:22][INFO] visual_prompt:  165: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[05/12 20:17:52][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7504,	0.3018 s / batch. (data: 8.18e-05). ETA=1:04:57, max mem: 7.0 GB 
[05/12 20:18:13][INFO] visual_prompt:  219: Epoch 24 / 100: avg data time: 2.06e-03, avg batch time: 0.3030, average train loss: 0.6803
[05/12 20:18:16][INFO] visual_prompt:  324: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1480, average loss: 0.7625
[05/12 20:18:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 98.00	
[05/12 20:18:31][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.566, 0.1483 s / batch. (data: 3.62e-05)max mem: 6.98685 GB 
[05/12 20:18:43][INFO] visual_prompt:  324: Inference (test):avg data time: 3.02e-05, avg batch time: 0.1477, average loss: 0.7844
[05/12 20:18:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.38	top5: 97.20	
[05/12 20:18:43][INFO] visual_prompt:  165: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[05/12 20:19:14][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6824,	0.3019 s / batch. (data: 8.01e-05). ETA=1:04:06, max mem: 7.0 GB 
[05/12 20:19:35][INFO] visual_prompt:  219: Epoch 25 / 100: avg data time: 2.00e-03, avg batch time: 0.3029, average train loss: 0.6653
[05/12 20:19:38][INFO] visual_prompt:  324: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1480, average loss: 0.7508
[05/12 20:19:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 98.00	
[05/12 20:19:53][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.538, 0.1486 s / batch. (data: 3.65e-05)max mem: 6.98685 GB 
[05/12 20:20:05][INFO] visual_prompt:  324: Inference (test):avg data time: 3.01e-05, avg batch time: 0.1478, average loss: 0.7664
[05/12 20:20:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.22	top5: 97.34	
[05/12 20:20:05][INFO] visual_prompt:  165: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[05/12 20:20:35][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7772,	0.3013 s / batch. (data: 8.23e-05). ETA=1:03:08, max mem: 7.0 GB 
[05/12 20:20:56][INFO] visual_prompt:  219: Epoch 26 / 100: avg data time: 1.61e-03, avg batch time: 0.3026, average train loss: 0.6845
[05/12 20:20:59][INFO] visual_prompt:  324: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1480, average loss: 0.7658
[05/12 20:20:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.17	top5: 98.00	
[05/12 20:21:15][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.475, 0.1484 s / batch. (data: 2.24e-05)max mem: 6.98685 GB 
[05/12 20:21:27][INFO] visual_prompt:  324: Inference (test):avg data time: 2.99e-05, avg batch time: 0.1478, average loss: 0.7800
[05/12 20:21:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.65	top5: 97.13	
[05/12 20:21:27][INFO] visual_prompt:  165: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[05/12 20:21:57][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.8607,	0.3015 s / batch. (data: 1.21e-04). ETA=1:02:19, max mem: 7.0 GB 
[05/12 20:22:18][INFO] visual_prompt:  219: Epoch 27 / 100: avg data time: 2.15e-03, avg batch time: 0.3031, average train loss: 0.6765
[05/12 20:22:21][INFO] visual_prompt:  324: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1480, average loss: 0.7665
[05/12 20:22:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 98.33	
[05/12 20:22:36][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.769, 0.1483 s / batch. (data: 1.98e-05)max mem: 6.98685 GB 
[05/12 20:22:48][INFO] visual_prompt:  324: Inference (test):avg data time: 3.00e-05, avg batch time: 0.1478, average loss: 0.7722
[05/12 20:22:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.84	top5: 97.45	
[05/12 20:22:48][INFO] visual_prompt:  165: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[05/12 20:23:19][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.9712,	0.3018 s / batch. (data: 1.14e-04). ETA=1:01:33, max mem: 7.0 GB 
[05/12 20:23:40][INFO] visual_prompt:  219: Epoch 28 / 100: avg data time: 2.17e-03, avg batch time: 0.3031, average train loss: 0.6706
[05/12 20:23:43][INFO] visual_prompt:  324: Inference (val):avg data time: 5.17e-05, avg batch time: 0.1479, average loss: 0.7723
[05/12 20:23:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 98.33	
[05/12 20:23:58][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.618, 0.1485 s / batch. (data: 2.10e-05)max mem: 6.98685 GB 
[05/12 20:24:10][INFO] visual_prompt:  324: Inference (test):avg data time: 3.42e-05, avg batch time: 0.1477, average loss: 0.7763
[05/12 20:24:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.36	top5: 97.55	
[05/12 20:24:10][INFO] visual_prompt:  165: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[05/12 20:24:40][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7030,	0.3020 s / batch. (data: 9.78e-05). ETA=1:00:44, max mem: 7.0 GB 
[05/12 20:25:01][INFO] visual_prompt:  219: Epoch 29 / 100: avg data time: 1.95e-03, avg batch time: 0.3028, average train loss: 0.6669
[05/12 20:25:04][INFO] visual_prompt:  324: Inference (val):avg data time: 5.26e-05, avg batch time: 0.1479, average loss: 0.7773
[05/12 20:25:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 98.00	
[05/12 20:25:19][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.367, 0.1484 s / batch. (data: 2.12e-05)max mem: 6.98685 GB 
[05/12 20:25:31][INFO] visual_prompt:  324: Inference (test):avg data time: 3.26e-05, avg batch time: 0.1477, average loss: 0.7789
[05/12 20:25:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.03	top5: 97.69	
[05/12 20:25:32][INFO] visual_prompt:  165: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[05/12 20:26:02][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5993,	0.3018 s / batch. (data: 1.94e-04). ETA=0:59:51, max mem: 7.0 GB 
[05/12 20:26:23][INFO] visual_prompt:  219: Epoch 30 / 100: avg data time: 2.08e-03, avg batch time: 0.3030, average train loss: 0.6770
[05/12 20:26:26][INFO] visual_prompt:  324: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1480, average loss: 0.7778
[05/12 20:26:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.83	top5: 97.83	
[05/12 20:26:41][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.630, 0.1486 s / batch. (data: 1.96e-05)max mem: 6.98685 GB 
[05/12 20:26:53][INFO] visual_prompt:  324: Inference (test):avg data time: 3.20e-05, avg batch time: 0.1477, average loss: 0.7959
[05/12 20:26:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.10	top5: 97.41	
[05/12 20:26:53][INFO] visual_prompt:  165: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[05/12 20:27:24][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4858,	0.3019 s / batch. (data: 1.15e-04). ETA=0:59:00, max mem: 7.0 GB 
[05/12 20:27:44][INFO] visual_prompt:  219: Epoch 31 / 100: avg data time: 2.03e-03, avg batch time: 0.3029, average train loss: 0.6658
[05/12 20:27:47][INFO] visual_prompt:  324: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1479, average loss: 0.7767
[05/12 20:27:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.67	
[05/12 20:28:03][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.530, 0.1485 s / batch. (data: 3.17e-05)max mem: 6.98685 GB 
[05/12 20:28:15][INFO] visual_prompt:  324: Inference (test):avg data time: 3.21e-05, avg batch time: 0.1477, average loss: 0.7810
[05/12 20:28:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.31	top5: 97.45	
[05/12 20:28:15][INFO] visual_prompt:  165: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[05/12 20:28:45][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6523,	0.3019 s / batch. (data: 9.47e-05). ETA=0:58:09, max mem: 7.0 GB 
[05/12 20:29:06][INFO] visual_prompt:  219: Epoch 32 / 100: avg data time: 2.20e-03, avg batch time: 0.3030, average train loss: 0.6645
[05/12 20:29:09][INFO] visual_prompt:  324: Inference (val):avg data time: 4.70e-05, avg batch time: 0.1479, average loss: 0.7533
[05/12 20:29:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 98.33	
[05/12 20:29:24][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.673, 0.1483 s / batch. (data: 1.98e-05)max mem: 6.98685 GB 
[05/12 20:29:36][INFO] visual_prompt:  324: Inference (test):avg data time: 2.58e-05, avg batch time: 0.1477, average loss: 0.7697
[05/12 20:29:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.08	top5: 97.51	
[05/12 20:29:36][INFO] visual_prompt:  165: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[05/12 20:30:07][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6418,	0.3016 s / batch. (data: 9.70e-05). ETA=0:57:15, max mem: 7.0 GB 
[05/12 20:30:28][INFO] visual_prompt:  219: Epoch 33 / 100: avg data time: 2.18e-03, avg batch time: 0.3031, average train loss: 0.6691
[05/12 20:30:31][INFO] visual_prompt:  324: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1480, average loss: 0.7716
[05/12 20:30:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 98.50	
[05/12 20:30:46][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.498, 0.1484 s / batch. (data: 1.93e-05)max mem: 6.98685 GB 
[05/12 20:30:58][INFO] visual_prompt:  324: Inference (test):avg data time: 2.90e-05, avg batch time: 0.1478, average loss: 0.7712
[05/12 20:30:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.34	top5: 97.62	
[05/12 20:30:58][INFO] visual_prompt:  165: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[05/12 20:31:29][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6048,	0.3019 s / batch. (data: 7.99e-05). ETA=0:56:28, max mem: 7.0 GB 
[05/12 20:31:49][INFO] visual_prompt:  219: Epoch 34 / 100: avg data time: 2.08e-03, avg batch time: 0.3031, average train loss: 0.6535
[05/12 20:31:53][INFO] visual_prompt:  324: Inference (val):avg data time: 3.79e-05, avg batch time: 0.1479, average loss: 0.7409
[05/12 20:31:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 97.83	
[05/12 20:32:08][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.943, 0.1487 s / batch. (data: 3.67e-05)max mem: 6.98685 GB 
[05/12 20:32:20][INFO] visual_prompt:  324: Inference (test):avg data time: 2.87e-05, avg batch time: 0.1478, average loss: 0.7673
[05/12 20:32:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.08	top5: 97.12	
[05/12 20:32:20][INFO] visual_prompt:  246: Best epoch 34: best metric: 0.827
[05/12 20:32:20][INFO] visual_prompt:  165: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[05/12 20:32:50][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6417,	0.3017 s / batch. (data: 1.74e-04). ETA=0:55:35, max mem: 7.0 GB 
[05/12 20:33:11][INFO] visual_prompt:  219: Epoch 35 / 100: avg data time: 1.60e-03, avg batch time: 0.3025, average train loss: 0.6654
[05/12 20:33:14][INFO] visual_prompt:  324: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1478, average loss: 0.7626
[05/12 20:33:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.50	
[05/12 20:33:29][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.520, 0.1484 s / batch. (data: 1.93e-05)max mem: 6.98685 GB 
[05/12 20:33:41][INFO] visual_prompt:  324: Inference (test):avg data time: 3.15e-05, avg batch time: 0.1478, average loss: 0.7807
[05/12 20:33:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.31	top5: 97.38	
[05/12 20:33:41][INFO] visual_prompt:  165: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[05/12 20:34:12][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6929,	0.3017 s / batch. (data: 7.82e-05). ETA=0:54:43, max mem: 7.0 GB 
[05/12 20:34:33][INFO] visual_prompt:  219: Epoch 36 / 100: avg data time: 1.60e-03, avg batch time: 0.3026, average train loss: 0.6492
[05/12 20:34:36][INFO] visual_prompt:  324: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1479, average loss: 0.7669
[05/12 20:34:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 98.67	
[05/12 20:34:51][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.714, 0.1484 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 20:35:03][INFO] visual_prompt:  324: Inference (test):avg data time: 2.61e-05, avg batch time: 0.1477, average loss: 0.7674
[05/12 20:35:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.33	top5: 97.70	
[05/12 20:35:03][INFO] visual_prompt:  165: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[05/12 20:35:33][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5850,	0.3014 s / batch. (data: 8.11e-05). ETA=0:53:49, max mem: 7.0 GB 
[05/12 20:35:54][INFO] visual_prompt:  219: Epoch 37 / 100: avg data time: 1.86e-03, avg batch time: 0.3028, average train loss: 0.6537
[05/12 20:35:57][INFO] visual_prompt:  324: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1480, average loss: 0.7338
[05/12 20:35:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 98.50	
[05/12 20:36:13][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.448, 0.1483 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 20:36:25][INFO] visual_prompt:  324: Inference (test):avg data time: 2.29e-05, avg batch time: 0.1477, average loss: 0.7582
[05/12 20:36:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.17	top5: 97.64	
[05/12 20:36:25][INFO] visual_prompt:  165: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[05/12 20:36:55][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5591,	0.3018 s / batch. (data: 1.04e-04). ETA=0:53:03, max mem: 7.0 GB 
[05/12 20:37:16][INFO] visual_prompt:  219: Epoch 38 / 100: avg data time: 2.10e-03, avg batch time: 0.3030, average train loss: 0.6518
[05/12 20:37:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1481, average loss: 0.7288
[05/12 20:37:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 98.33	
[05/12 20:37:34][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.908, 0.1485 s / batch. (data: 2.07e-05)max mem: 6.98685 GB 
[05/12 20:37:46][INFO] visual_prompt:  324: Inference (test):avg data time: 2.68e-05, avg batch time: 0.1478, average loss: 0.7613
[05/12 20:37:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.90	top5: 97.58	
[05/12 20:37:46][INFO] visual_prompt:  165: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[05/12 20:38:17][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7272,	0.3015 s / batch. (data: 1.18e-04). ETA=0:52:09, max mem: 7.0 GB 
[05/12 20:38:38][INFO] visual_prompt:  219: Epoch 39 / 100: avg data time: 2.21e-03, avg batch time: 0.3031, average train loss: 0.6412
[05/12 20:38:41][INFO] visual_prompt:  324: Inference (val):avg data time: 4.48e-05, avg batch time: 0.1480, average loss: 0.7449
[05/12 20:38:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 98.33	
[05/12 20:38:56][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.711, 0.1484 s / batch. (data: 2.10e-05)max mem: 6.98685 GB 
[05/12 20:39:08][INFO] visual_prompt:  324: Inference (test):avg data time: 2.60e-05, avg batch time: 0.1477, average loss: 0.7684
[05/12 20:39:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.27	top5: 97.72	
[05/12 20:39:08][INFO] visual_prompt:  165: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[05/12 20:39:38][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6397,	0.3018 s / batch. (data: 1.12e-04). ETA=0:51:21, max mem: 7.0 GB 
[05/12 20:39:59][INFO] visual_prompt:  219: Epoch 40 / 100: avg data time: 2.13e-03, avg batch time: 0.3030, average train loss: 0.6533
[05/12 20:40:02][INFO] visual_prompt:  324: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1480, average loss: 0.7406
[05/12 20:40:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.50	top5: 97.67	
[05/12 20:40:17][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.882, 0.1485 s / batch. (data: 3.65e-05)max mem: 6.98685 GB 
[05/12 20:40:30][INFO] visual_prompt:  324: Inference (test):avg data time: 3.25e-05, avg batch time: 0.1477, average loss: 0.7536
[05/12 20:40:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.12	top5: 97.72	
[05/12 20:40:30][INFO] visual_prompt:  165: Training 41 / 100 epoch, with learning rate 0.1875
[05/12 20:41:00][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4377,	0.3013 s / batch. (data: 7.70e-05). ETA=0:50:24, max mem: 7.0 GB 
[05/12 20:41:21][INFO] visual_prompt:  219: Epoch 41 / 100: avg data time: 2.16e-03, avg batch time: 0.3031, average train loss: 0.6378
[05/12 20:41:24][INFO] visual_prompt:  324: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1479, average loss: 0.7447
[05/12 20:41:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 98.50	
[05/12 20:41:39][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.484, 0.1483 s / batch. (data: 2.03e-05)max mem: 6.98685 GB 
[05/12 20:41:51][INFO] visual_prompt:  324: Inference (test):avg data time: 2.87e-05, avg batch time: 0.1477, average loss: 0.7491
[05/12 20:41:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.93	top5: 97.67	
[05/12 20:41:51][INFO] visual_prompt:  165: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[05/12 20:42:22][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6670,	0.3019 s / batch. (data: 8.08e-05). ETA=0:49:39, max mem: 7.0 GB 
[05/12 20:42:43][INFO] visual_prompt:  219: Epoch 42 / 100: avg data time: 2.22e-03, avg batch time: 0.3032, average train loss: 0.6489
[05/12 20:42:46][INFO] visual_prompt:  324: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1479, average loss: 0.7330
[05/12 20:42:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 98.33	
[05/12 20:43:01][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.678, 0.1486 s / batch. (data: 3.60e-05)max mem: 6.98685 GB 
[05/12 20:43:13][INFO] visual_prompt:  324: Inference (test):avg data time: 3.00e-05, avg batch time: 0.1477, average loss: 0.7484
[05/12 20:43:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.83	top5: 97.69	
[05/12 20:43:13][INFO] visual_prompt:  165: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[05/12 20:43:43][INFO] visual_prompt:  213: 	Training 100/169. train loss: 1.0605,	0.3018 s / batch. (data: 1.63e-04). ETA=0:48:47, max mem: 7.0 GB 
[05/12 20:44:04][INFO] visual_prompt:  219: Epoch 43 / 100: avg data time: 2.14e-03, avg batch time: 0.3031, average train loss: 0.6373
[05/12 20:44:07][INFO] visual_prompt:  324: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1478, average loss: 0.7284
[05/12 20:44:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 98.17	
[05/12 20:44:22][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.574, 0.1483 s / batch. (data: 3.58e-05)max mem: 6.98685 GB 
[05/12 20:44:35][INFO] visual_prompt:  324: Inference (test):avg data time: 2.81e-05, avg batch time: 0.1477, average loss: 0.7621
[05/12 20:44:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.90	top5: 97.39	
[05/12 20:44:35][INFO] visual_prompt:  165: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[05/12 20:45:05][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7159,	0.3015 s / batch. (data: 8.01e-05). ETA=0:47:53, max mem: 7.0 GB 
[05/12 20:45:26][INFO] visual_prompt:  219: Epoch 44 / 100: avg data time: 2.03e-03, avg batch time: 0.3030, average train loss: 0.6456
[05/12 20:45:29][INFO] visual_prompt:  324: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1479, average loss: 0.7630
[05/12 20:45:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 97.83	
[05/12 20:45:44][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.316, 0.1484 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 20:45:56][INFO] visual_prompt:  324: Inference (test):avg data time: 3.64e-05, avg batch time: 0.1478, average loss: 0.7855
[05/12 20:45:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.22	top5: 97.36	
[05/12 20:45:56][INFO] visual_prompt:  165: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[05/12 20:46:27][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6078,	0.3019 s / batch. (data: 7.92e-05). ETA=0:47:06, max mem: 7.0 GB 
[05/12 20:46:47][INFO] visual_prompt:  219: Epoch 45 / 100: avg data time: 1.62e-03, avg batch time: 0.3026, average train loss: 0.6286
[05/12 20:46:51][INFO] visual_prompt:  324: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1480, average loss: 0.7368
[05/12 20:46:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 98.17	
[05/12 20:47:06][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.817, 0.1484 s / batch. (data: 3.70e-05)max mem: 6.98685 GB 
[05/12 20:47:18][INFO] visual_prompt:  324: Inference (test):avg data time: 2.83e-05, avg batch time: 0.1477, average loss: 0.7602
[05/12 20:47:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.10	top5: 97.79	
[05/12 20:47:18][INFO] visual_prompt:  165: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[05/12 20:47:48][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7325,	0.3018 s / batch. (data: 8.73e-05). ETA=0:46:15, max mem: 7.0 GB 
[05/12 20:48:09][INFO] visual_prompt:  219: Epoch 46 / 100: avg data time: 1.79e-03, avg batch time: 0.3027, average train loss: 0.6277
[05/12 20:48:12][INFO] visual_prompt:  324: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1480, average loss: 0.7023
[05/12 20:48:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 98.33	
[05/12 20:48:27][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.396, 0.1483 s / batch. (data: 2.22e-05)max mem: 6.98685 GB 
[05/12 20:48:40][INFO] visual_prompt:  324: Inference (test):avg data time: 2.78e-05, avg batch time: 0.1477, average loss: 0.7400
[05/12 20:48:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.57	top5: 97.48	
[05/12 20:48:40][INFO] visual_prompt:  246: Best epoch 46: best metric: 0.835
[05/12 20:48:40][INFO] visual_prompt:  165: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[05/12 20:49:10][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4714,	0.3018 s / batch. (data: 1.03e-04). ETA=0:45:24, max mem: 7.0 GB 
[05/12 20:49:31][INFO] visual_prompt:  219: Epoch 47 / 100: avg data time: 2.16e-03, avg batch time: 0.3030, average train loss: 0.6207
[05/12 20:49:34][INFO] visual_prompt:  324: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1479, average loss: 0.7264
[05/12 20:49:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 98.50	
[05/12 20:49:49][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.598, 0.1484 s / batch. (data: 3.77e-05)max mem: 6.98685 GB 
[05/12 20:50:01][INFO] visual_prompt:  324: Inference (test):avg data time: 2.76e-05, avg batch time: 0.1477, average loss: 0.7480
[05/12 20:50:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.05	top5: 97.95	
[05/12 20:50:01][INFO] visual_prompt:  165: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[05/12 20:50:32][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.8202,	0.3015 s / batch. (data: 1.04e-04). ETA=0:44:29, max mem: 7.0 GB 
[05/12 20:50:53][INFO] visual_prompt:  219: Epoch 48 / 100: avg data time: 2.22e-03, avg batch time: 0.3031, average train loss: 0.6165
[05/12 20:50:56][INFO] visual_prompt:  324: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1480, average loss: 0.7407
[05/12 20:50:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 98.33	
[05/12 20:51:11][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.486, 0.1484 s / batch. (data: 2.05e-05)max mem: 6.98685 GB 
[05/12 20:51:23][INFO] visual_prompt:  324: Inference (test):avg data time: 2.94e-05, avg batch time: 0.1477, average loss: 0.7520
[05/12 20:51:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.15	top5: 97.81	
[05/12 20:51:23][INFO] visual_prompt:  165: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[05/12 20:51:53][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6020,	0.3016 s / batch. (data: 2.76e-04). ETA=0:43:40, max mem: 7.0 GB 
[05/12 20:52:14][INFO] visual_prompt:  219: Epoch 49 / 100: avg data time: 2.11e-03, avg batch time: 0.3030, average train loss: 0.6200
[05/12 20:52:17][INFO] visual_prompt:  324: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1480, average loss: 0.7250
[05/12 20:52:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 98.17	
[05/12 20:52:32][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.555, 0.1485 s / batch. (data: 3.62e-05)max mem: 6.98685 GB 
[05/12 20:52:45][INFO] visual_prompt:  324: Inference (test):avg data time: 2.99e-05, avg batch time: 0.1478, average loss: 0.7365
[05/12 20:52:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.78	top5: 97.88	
[05/12 20:52:45][INFO] visual_prompt:  165: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[05/12 20:53:15][INFO] visual_prompt:  213: 	Training 100/169. train loss: 1.0098,	0.3018 s / batch. (data: 1.04e-04). ETA=0:42:51, max mem: 7.0 GB 
[05/12 20:53:36][INFO] visual_prompt:  219: Epoch 50 / 100: avg data time: 2.18e-03, avg batch time: 0.3031, average train loss: 0.6113
[05/12 20:53:39][INFO] visual_prompt:  324: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1478, average loss: 0.7286
[05/12 20:53:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 98.00	
[05/12 20:53:54][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.418, 0.1484 s / batch. (data: 3.65e-05)max mem: 6.98685 GB 
[05/12 20:54:06][INFO] visual_prompt:  324: Inference (test):avg data time: 3.19e-05, avg batch time: 0.1477, average loss: 0.7474
[05/12 20:54:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.46	top5: 97.69	
[05/12 20:54:06][INFO] visual_prompt:  165: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[05/12 20:54:37][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4959,	0.3015 s / batch. (data: 1.06e-04). ETA=0:41:57, max mem: 7.0 GB 
[05/12 20:54:57][INFO] visual_prompt:  219: Epoch 51 / 100: avg data time: 1.66e-03, avg batch time: 0.3026, average train loss: 0.6100
[05/12 20:55:01][INFO] visual_prompt:  324: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1480, average loss: 0.7189
[05/12 20:55:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 98.83	
[05/12 20:55:16][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.417, 0.1485 s / batch. (data: 2.12e-05)max mem: 6.98685 GB 
[05/12 20:55:28][INFO] visual_prompt:  324: Inference (test):avg data time: 3.35e-05, avg batch time: 0.1477, average loss: 0.7372
[05/12 20:55:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.65	top5: 97.81	
[05/12 20:55:28][INFO] visual_prompt:  165: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[05/12 20:55:58][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5837,	0.3018 s / batch. (data: 1.20e-04). ETA=0:41:08, max mem: 7.0 GB 
[05/12 20:56:19][INFO] visual_prompt:  219: Epoch 52 / 100: avg data time: 2.18e-03, avg batch time: 0.3032, average train loss: 0.6074
[05/12 20:56:22][INFO] visual_prompt:  324: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1481, average loss: 0.7524
[05/12 20:56:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.83	
[05/12 20:56:37][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.734, 0.1484 s / batch. (data: 1.93e-05)max mem: 6.98685 GB 
[05/12 20:56:49][INFO] visual_prompt:  324: Inference (test):avg data time: 2.84e-05, avg batch time: 0.1478, average loss: 0.7683
[05/12 20:56:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.88	top5: 97.46	
[05/12 20:56:49][INFO] visual_prompt:  165: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[05/12 20:57:20][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.3807,	0.3018 s / batch. (data: 9.73e-05). ETA=0:40:17, max mem: 7.0 GB 
[05/12 20:57:41][INFO] visual_prompt:  219: Epoch 53 / 100: avg data time: 2.19e-03, avg batch time: 0.3032, average train loss: 0.6082
[05/12 20:57:44][INFO] visual_prompt:  324: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1479, average loss: 0.7226
[05/12 20:57:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 98.33	
[05/12 20:57:59][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.459, 0.1485 s / batch. (data: 3.65e-05)max mem: 6.98685 GB 
[05/12 20:58:11][INFO] visual_prompt:  324: Inference (test):avg data time: 3.05e-05, avg batch time: 0.1478, average loss: 0.7325
[05/12 20:58:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.57	top5: 97.83	
[05/12 20:58:11][INFO] visual_prompt:  165: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[05/12 20:58:42][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7852,	0.3016 s / batch. (data: 8.15e-05). ETA=0:39:25, max mem: 7.0 GB 
[05/12 20:59:02][INFO] visual_prompt:  219: Epoch 54 / 100: avg data time: 2.23e-03, avg batch time: 0.3031, average train loss: 0.5965
[05/12 20:59:06][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1478, average loss: 0.7272
[05/12 20:59:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 98.33	
[05/12 20:59:21][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.808, 0.1484 s / batch. (data: 1.96e-05)max mem: 6.98685 GB 
[05/12 20:59:33][INFO] visual_prompt:  324: Inference (test):avg data time: 2.77e-05, avg batch time: 0.1477, average loss: 0.7413
[05/12 20:59:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.90	top5: 97.64	
[05/12 20:59:33][INFO] visual_prompt:  165: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[05/12 21:00:03][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7071,	0.3017 s / batch. (data: 7.82e-05). ETA=0:38:35, max mem: 7.0 GB 
[05/12 21:00:24][INFO] visual_prompt:  219: Epoch 55 / 100: avg data time: 1.79e-03, avg batch time: 0.3027, average train loss: 0.6011
[05/12 21:00:27][INFO] visual_prompt:  324: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1478, average loss: 0.7098
[05/12 21:00:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 98.33	
[05/12 21:00:42][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.573, 0.1486 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 21:00:54][INFO] visual_prompt:  324: Inference (test):avg data time: 2.81e-05, avg batch time: 0.1477, average loss: 0.7317
[05/12 21:00:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.50	top5: 97.53	
[05/12 21:00:54][INFO] visual_prompt:  165: Training 56 / 100 epoch, with learning rate 0.125
[05/12 21:01:25][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7490,	0.3017 s / batch. (data: 7.89e-05). ETA=0:37:44, max mem: 7.0 GB 
[05/12 21:01:46][INFO] visual_prompt:  219: Epoch 56 / 100: avg data time: 1.64e-03, avg batch time: 0.3027, average train loss: 0.5980
[05/12 21:01:49][INFO] visual_prompt:  324: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1479, average loss: 0.7289
[05/12 21:01:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 98.67	
[05/12 21:02:04][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.384, 0.1485 s / batch. (data: 3.62e-05)max mem: 6.98685 GB 
[05/12 21:02:16][INFO] visual_prompt:  324: Inference (test):avg data time: 2.97e-05, avg batch time: 0.1478, average loss: 0.7416
[05/12 21:02:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.62	top5: 97.79	
[05/12 21:02:16][INFO] visual_prompt:  165: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[05/12 21:02:47][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6967,	0.3019 s / batch. (data: 1.43e-04). ETA=0:36:54, max mem: 7.0 GB 
[05/12 21:03:07][INFO] visual_prompt:  219: Epoch 57 / 100: avg data time: 1.97e-03, avg batch time: 0.3029, average train loss: 0.5920
[05/12 21:03:11][INFO] visual_prompt:  324: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1481, average loss: 0.7153
[05/12 21:03:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 98.17	
[05/12 21:03:26][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.435, 0.1485 s / batch. (data: 2.29e-05)max mem: 6.98685 GB 
[05/12 21:03:38][INFO] visual_prompt:  324: Inference (test):avg data time: 3.05e-05, avg batch time: 0.1478, average loss: 0.7236
[05/12 21:03:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.47	top5: 97.83	
[05/12 21:03:38][INFO] visual_prompt:  165: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[05/12 21:04:08][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6306,	0.3019 s / batch. (data: 2.26e-04). ETA=0:36:03, max mem: 7.0 GB 
[05/12 21:04:29][INFO] visual_prompt:  219: Epoch 58 / 100: avg data time: 2.06e-03, avg batch time: 0.3030, average train loss: 0.5907
[05/12 21:04:32][INFO] visual_prompt:  324: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1480, average loss: 0.7192
[05/12 21:04:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 98.67	
[05/12 21:04:47][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.413, 0.1488 s / batch. (data: 2.07e-05)max mem: 6.98685 GB 
[05/12 21:05:00][INFO] visual_prompt:  324: Inference (test):avg data time: 3.12e-05, avg batch time: 0.1478, average loss: 0.7308
[05/12 21:05:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.98	top5: 97.79	
[05/12 21:05:00][INFO] visual_prompt:  165: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[05/12 21:05:30][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4945,	0.3018 s / batch. (data: 9.42e-05). ETA=0:35:12, max mem: 7.0 GB 
[05/12 21:05:51][INFO] visual_prompt:  219: Epoch 59 / 100: avg data time: 2.06e-03, avg batch time: 0.3030, average train loss: 0.5955
[05/12 21:05:54][INFO] visual_prompt:  324: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1479, average loss: 0.7132
[05/12 21:05:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 98.33	
[05/12 21:06:09][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.522, 0.1487 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 21:06:21][INFO] visual_prompt:  324: Inference (test):avg data time: 2.96e-05, avg batch time: 0.1478, average loss: 0.7402
[05/12 21:06:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.81	top5: 97.65	
[05/12 21:06:21][INFO] visual_prompt:  165: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[05/12 21:06:52][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7334,	0.3019 s / batch. (data: 9.75e-05). ETA=0:34:21, max mem: 7.0 GB 
[05/12 21:07:13][INFO] visual_prompt:  219: Epoch 60 / 100: avg data time: 2.20e-03, avg batch time: 0.3032, average train loss: 0.5900
[05/12 21:07:16][INFO] visual_prompt:  324: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1480, average loss: 0.7067
[05/12 21:07:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 98.50	
[05/12 21:07:31][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.554, 0.1486 s / batch. (data: 3.72e-05)max mem: 6.98685 GB 
[05/12 21:07:43][INFO] visual_prompt:  324: Inference (test):avg data time: 2.88e-05, avg batch time: 0.1478, average loss: 0.7349
[05/12 21:07:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.33	top5: 97.81	
[05/12 21:07:43][INFO] visual_prompt:  165: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[05/12 21:08:13][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5294,	0.3021 s / batch. (data: 1.97e-04). ETA=0:33:31, max mem: 7.0 GB 
[05/12 21:08:34][INFO] visual_prompt:  219: Epoch 61 / 100: avg data time: 2.03e-03, avg batch time: 0.3030, average train loss: 0.5791
[05/12 21:08:37][INFO] visual_prompt:  324: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1479, average loss: 0.7044
[05/12 21:08:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 98.67	
[05/12 21:08:52][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.520, 0.1488 s / batch. (data: 1.98e-05)max mem: 6.98685 GB 
[05/12 21:09:05][INFO] visual_prompt:  324: Inference (test):avg data time: 3.09e-05, avg batch time: 0.1478, average loss: 0.7162
[05/12 21:09:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.72	top5: 97.98	
[05/12 21:09:05][INFO] visual_prompt:  165: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[05/12 21:09:35][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6444,	0.3017 s / batch. (data: 9.82e-05). ETA=0:32:38, max mem: 7.0 GB 
[05/12 21:09:56][INFO] visual_prompt:  219: Epoch 62 / 100: avg data time: 1.63e-03, avg batch time: 0.3027, average train loss: 0.5830
[05/12 21:09:59][INFO] visual_prompt:  324: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1479, average loss: 0.7060
[05/12 21:09:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 98.67	
[05/12 21:10:14][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.447, 0.1484 s / batch. (data: 2.12e-05)max mem: 6.98685 GB 
[05/12 21:10:26][INFO] visual_prompt:  324: Inference (test):avg data time: 3.16e-05, avg batch time: 0.1478, average loss: 0.7225
[05/12 21:10:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.55	top5: 97.83	
[05/12 21:10:26][INFO] visual_prompt:  165: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[05/12 21:10:57][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5007,	0.3019 s / batch. (data: 7.82e-05). ETA=0:31:48, max mem: 7.0 GB 
[05/12 21:11:17][INFO] visual_prompt:  219: Epoch 63 / 100: avg data time: 1.59e-03, avg batch time: 0.3026, average train loss: 0.5775
[05/12 21:11:21][INFO] visual_prompt:  324: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1480, average loss: 0.7060
[05/12 21:11:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 97.83	
[05/12 21:11:36][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.488, 0.1485 s / batch. (data: 2.24e-05)max mem: 6.98685 GB 
[05/12 21:11:48][INFO] visual_prompt:  324: Inference (test):avg data time: 2.90e-05, avg batch time: 0.1478, average loss: 0.7228
[05/12 21:11:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.29	top5: 97.77	
[05/12 21:11:48][INFO] visual_prompt:  165: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[05/12 21:12:18][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4855,	0.3016 s / batch. (data: 7.99e-05). ETA=0:30:56, max mem: 7.0 GB 
[05/12 21:12:39][INFO] visual_prompt:  219: Epoch 64 / 100: avg data time: 1.66e-03, avg batch time: 0.3027, average train loss: 0.5774
[05/12 21:12:42][INFO] visual_prompt:  324: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1479, average loss: 0.7074
[05/12 21:12:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 98.33	
[05/12 21:12:57][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.490, 0.1485 s / batch. (data: 1.84e-05)max mem: 6.98685 GB 
[05/12 21:13:09][INFO] visual_prompt:  324: Inference (test):avg data time: 2.90e-05, avg batch time: 0.1478, average loss: 0.7138
[05/12 21:13:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.93	top5: 97.79	
[05/12 21:13:10][INFO] visual_prompt:  165: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[05/12 21:13:40][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5752,	0.3019 s / batch. (data: 8.15e-05). ETA=0:30:06, max mem: 7.0 GB 
[05/12 21:14:01][INFO] visual_prompt:  219: Epoch 65 / 100: avg data time: 1.88e-03, avg batch time: 0.3030, average train loss: 0.5575
[05/12 21:14:04][INFO] visual_prompt:  324: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1478, average loss: 0.6990
[05/12 21:14:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.50	
[05/12 21:14:19][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.586, 0.1488 s / batch. (data: 1.96e-05)max mem: 6.98685 GB 
[05/12 21:14:31][INFO] visual_prompt:  324: Inference (test):avg data time: 2.65e-05, avg batch time: 0.1478, average loss: 0.7167
[05/12 21:14:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.17	top5: 97.86	
[05/12 21:14:31][INFO] visual_prompt:  246: Best epoch 65: best metric: 0.848
[05/12 21:14:31][INFO] visual_prompt:  165: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[05/12 21:15:02][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4466,	0.3013 s / batch. (data: 8.49e-05). ETA=0:29:12, max mem: 7.0 GB 
[05/12 21:15:22][INFO] visual_prompt:  219: Epoch 66 / 100: avg data time: 1.62e-03, avg batch time: 0.3026, average train loss: 0.5718
[05/12 21:15:26][INFO] visual_prompt:  324: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1479, average loss: 0.6941
[05/12 21:15:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 98.67	
[05/12 21:15:41][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.477, 0.1485 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 21:15:53][INFO] visual_prompt:  324: Inference (test):avg data time: 2.98e-05, avg batch time: 0.1477, average loss: 0.7066
[05/12 21:15:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.35	top5: 97.98	
[05/12 21:15:53][INFO] visual_prompt:  165: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[05/12 21:16:23][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5168,	0.3017 s / batch. (data: 7.70e-05). ETA=0:28:23, max mem: 7.0 GB 
[05/12 21:16:44][INFO] visual_prompt:  219: Epoch 67 / 100: avg data time: 1.67e-03, avg batch time: 0.3026, average train loss: 0.5630
[05/12 21:16:47][INFO] visual_prompt:  324: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1479, average loss: 0.6975
[05/12 21:16:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 98.50	
[05/12 21:17:02][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.616, 0.1484 s / batch. (data: 2.05e-05)max mem: 6.98685 GB 
[05/12 21:17:14][INFO] visual_prompt:  324: Inference (test):avg data time: 2.74e-05, avg batch time: 0.1477, average loss: 0.7127
[05/12 21:17:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.17	top5: 97.72	
[05/12 21:17:14][INFO] visual_prompt:  165: Training 68 / 100 epoch, with learning rate 0.074157919615525
[05/12 21:17:45][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4663,	0.3017 s / batch. (data: 1.20e-04). ETA=0:27:32, max mem: 7.0 GB 
[05/12 21:18:06][INFO] visual_prompt:  219: Epoch 68 / 100: avg data time: 2.18e-03, avg batch time: 0.3031, average train loss: 0.5569
[05/12 21:18:09][INFO] visual_prompt:  324: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1481, average loss: 0.6937
[05/12 21:18:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.67	top5: 98.67	
[05/12 21:18:24][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.588, 0.1483 s / batch. (data: 1.91e-05)max mem: 6.98685 GB 
[05/12 21:18:36][INFO] visual_prompt:  324: Inference (test):avg data time: 2.85e-05, avg batch time: 0.1477, average loss: 0.7102
[05/12 21:18:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.76	top5: 97.79	
[05/12 21:18:36][INFO] visual_prompt:  165: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[05/12 21:19:07][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5713,	0.3016 s / batch. (data: 7.68e-05). ETA=0:26:40, max mem: 7.0 GB 
[05/12 21:19:27][INFO] visual_prompt:  219: Epoch 69 / 100: avg data time: 1.71e-03, avg batch time: 0.3026, average train loss: 0.5574
[05/12 21:19:30][INFO] visual_prompt:  324: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1478, average loss: 0.6944
[05/12 21:19:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 98.33	
[05/12 21:19:46][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.573, 0.1486 s / batch. (data: 2.12e-05)max mem: 6.98685 GB 
[05/12 21:19:58][INFO] visual_prompt:  324: Inference (test):avg data time: 2.98e-05, avg batch time: 0.1477, average loss: 0.7094
[05/12 21:19:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.29	top5: 97.93	
[05/12 21:19:58][INFO] visual_prompt:  165: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[05/12 21:20:28][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.8981,	0.3020 s / batch. (data: 9.35e-05). ETA=0:25:51, max mem: 7.0 GB 
[05/12 21:20:49][INFO] visual_prompt:  219: Epoch 70 / 100: avg data time: 2.09e-03, avg batch time: 0.3030, average train loss: 0.5552
[05/12 21:20:52][INFO] visual_prompt:  324: Inference (val):avg data time: 4.28e-05, avg batch time: 0.1478, average loss: 0.6928
[05/12 21:20:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.33	
[05/12 21:21:07][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.545, 0.1484 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 21:21:19][INFO] visual_prompt:  324: Inference (test):avg data time: 2.80e-05, avg batch time: 0.1477, average loss: 0.7088
[05/12 21:21:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.23	top5: 97.65	
[05/12 21:21:19][INFO] visual_prompt:  165: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[05/12 21:21:50][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5796,	0.3013 s / batch. (data: 9.06e-05). ETA=0:24:57, max mem: 7.0 GB 
[05/12 21:22:11][INFO] visual_prompt:  219: Epoch 71 / 100: avg data time: 2.18e-03, avg batch time: 0.3031, average train loss: 0.5590
[05/12 21:22:14][INFO] visual_prompt:  324: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1482, average loss: 0.6915
[05/12 21:22:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.00	
[05/12 21:22:29][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.538, 0.1485 s / batch. (data: 1.98e-05)max mem: 6.98685 GB 
[05/12 21:22:41][INFO] visual_prompt:  324: Inference (test):avg data time: 2.81e-05, avg batch time: 0.1477, average loss: 0.7048
[05/12 21:22:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.31	top5: 97.95	
[05/12 21:22:41][INFO] visual_prompt:  165: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[05/12 21:23:12][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5872,	0.3013 s / batch. (data: 8.25e-05). ETA=0:24:06, max mem: 7.0 GB 
[05/12 21:23:32][INFO] visual_prompt:  219: Epoch 72 / 100: avg data time: 2.17e-03, avg batch time: 0.3031, average train loss: 0.5498
[05/12 21:23:36][INFO] visual_prompt:  324: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1479, average loss: 0.6938
[05/12 21:23:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.00	
[05/12 21:23:51][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.664, 0.1485 s / batch. (data: 1.96e-05)max mem: 6.98685 GB 
[05/12 21:24:03][INFO] visual_prompt:  324: Inference (test):avg data time: 2.89e-05, avg batch time: 0.1477, average loss: 0.7056
[05/12 21:24:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.69	top5: 97.91	
[05/12 21:24:03][INFO] visual_prompt:  165: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[05/12 21:24:33][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5706,	0.3015 s / batch. (data: 9.94e-05). ETA=0:23:16, max mem: 7.0 GB 
[05/12 21:24:54][INFO] visual_prompt:  219: Epoch 73 / 100: avg data time: 1.62e-03, avg batch time: 0.3025, average train loss: 0.5509
[05/12 21:24:57][INFO] visual_prompt:  324: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1481, average loss: 0.6924
[05/12 21:24:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.50	
[05/12 21:25:12][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.475, 0.1484 s / batch. (data: 1.96e-05)max mem: 6.98685 GB 
[05/12 21:25:24][INFO] visual_prompt:  324: Inference (test):avg data time: 3.08e-05, avg batch time: 0.1477, average loss: 0.6984
[05/12 21:25:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.40	top5: 97.91	
[05/12 21:25:25][INFO] visual_prompt:  165: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[05/12 21:25:55][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4476,	0.3018 s / batch. (data: 1.58e-04). ETA=0:22:27, max mem: 7.0 GB 
[05/12 21:26:16][INFO] visual_prompt:  219: Epoch 74 / 100: avg data time: 2.17e-03, avg batch time: 0.3031, average train loss: 0.5391
[05/12 21:26:19][INFO] visual_prompt:  324: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1481, average loss: 0.6747
[05/12 21:26:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.67	top5: 98.33	
[05/12 21:26:34][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.571, 0.1486 s / batch. (data: 2.15e-05)max mem: 6.98685 GB 
[05/12 21:26:46][INFO] visual_prompt:  324: Inference (test):avg data time: 3.20e-05, avg batch time: 0.1477, average loss: 0.6948
[05/12 21:26:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.07	top5: 97.89	
[05/12 21:26:46][INFO] visual_prompt:  165: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[05/12 21:27:17][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4726,	0.3014 s / batch. (data: 7.96e-05). ETA=0:21:34, max mem: 7.0 GB 
[05/12 21:27:37][INFO] visual_prompt:  219: Epoch 75 / 100: avg data time: 2.15e-03, avg batch time: 0.3031, average train loss: 0.5368
[05/12 21:27:41][INFO] visual_prompt:  324: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1482, average loss: 0.6844
[05/12 21:27:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.50	
[05/12 21:27:56][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.447, 0.1486 s / batch. (data: 3.74e-05)max mem: 6.98685 GB 
[05/12 21:28:08][INFO] visual_prompt:  324: Inference (test):avg data time: 2.99e-05, avg batch time: 0.1478, average loss: 0.6981
[05/12 21:28:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.14	top5: 97.84	
[05/12 21:28:08][INFO] visual_prompt:  165: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[05/12 21:28:38][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6344,	0.3016 s / batch. (data: 1.82e-04). ETA=0:20:43, max mem: 7.0 GB 
[05/12 21:28:59][INFO] visual_prompt:  219: Epoch 76 / 100: avg data time: 2.22e-03, avg batch time: 0.3032, average train loss: 0.5309
[05/12 21:29:02][INFO] visual_prompt:  324: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1479, average loss: 0.6840
[05/12 21:29:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.50	
[05/12 21:29:17][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.536, 0.1485 s / batch. (data: 2.17e-05)max mem: 6.98685 GB 
[05/12 21:29:29][INFO] visual_prompt:  324: Inference (test):avg data time: 3.08e-05, avg batch time: 0.1477, average loss: 0.6957
[05/12 21:29:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.11	top5: 97.86	
[05/12 21:29:29][INFO] visual_prompt:  165: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[05/12 21:30:00][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4440,	0.3017 s / batch. (data: 7.51e-05). ETA=0:19:53, max mem: 7.0 GB 
[05/12 21:30:21][INFO] visual_prompt:  219: Epoch 77 / 100: avg data time: 2.23e-03, avg batch time: 0.3031, average train loss: 0.5397
[05/12 21:30:24][INFO] visual_prompt:  324: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1478, average loss: 0.6864
[05/12 21:30:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.67	top5: 98.50	
[05/12 21:30:39][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.553, 0.1484 s / batch. (data: 3.67e-05)max mem: 6.98685 GB 
[05/12 21:30:51][INFO] visual_prompt:  324: Inference (test):avg data time: 3.17e-05, avg batch time: 0.1477, average loss: 0.6969
[05/12 21:30:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.21	top5: 97.81	
[05/12 21:30:51][INFO] visual_prompt:  165: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[05/12 21:31:22][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4715,	0.3017 s / batch. (data: 7.94e-05). ETA=0:19:02, max mem: 7.0 GB 
[05/12 21:31:42][INFO] visual_prompt:  219: Epoch 78 / 100: avg data time: 1.90e-03, avg batch time: 0.3028, average train loss: 0.5289
[05/12 21:31:46][INFO] visual_prompt:  324: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1478, average loss: 0.6826
[05/12 21:31:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 98.50	
[05/12 21:32:01][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.564, 0.1485 s / batch. (data: 1.88e-05)max mem: 6.98685 GB 
[05/12 21:32:13][INFO] visual_prompt:  324: Inference (test):avg data time: 2.99e-05, avg batch time: 0.1477, average loss: 0.6924
[05/12 21:32:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.05	top5: 97.86	
[05/12 21:32:13][INFO] visual_prompt:  165: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[05/12 21:32:43][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6094,	0.3018 s / batch. (data: 7.87e-05). ETA=0:18:11, max mem: 7.0 GB 
[05/12 21:33:04][INFO] visual_prompt:  219: Epoch 79 / 100: avg data time: 2.22e-03, avg batch time: 0.3031, average train loss: 0.5277
[05/12 21:33:07][INFO] visual_prompt:  324: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1478, average loss: 0.6764
[05/12 21:33:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.50	
[05/12 21:33:22][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.580, 0.1484 s / batch. (data: 1.15e-04)max mem: 6.98685 GB 
[05/12 21:33:34][INFO] visual_prompt:  324: Inference (test):avg data time: 4.37e-05, avg batch time: 0.1478, average loss: 0.6958
[05/12 21:33:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.76	top5: 97.81	
[05/12 21:33:35][INFO] visual_prompt:  165: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[05/12 21:34:05][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.3811,	0.3016 s / batch. (data: 1.34e-04). ETA=0:17:20, max mem: 7.0 GB 
[05/12 21:34:26][INFO] visual_prompt:  219: Epoch 80 / 100: avg data time: 2.27e-03, avg batch time: 0.3032, average train loss: 0.5305
[05/12 21:34:29][INFO] visual_prompt:  324: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1480, average loss: 0.6815
[05/12 21:34:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 98.33	
[05/12 21:34:44][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.482, 0.1485 s / batch. (data: 3.72e-05)max mem: 6.98685 GB 
[05/12 21:34:56][INFO] visual_prompt:  324: Inference (test):avg data time: 3.31e-05, avg batch time: 0.1478, average loss: 0.6924
[05/12 21:34:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.30	top5: 97.84	
[05/12 21:34:56][INFO] visual_prompt:  165: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[05/12 21:35:27][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5410,	0.3015 s / batch. (data: 1.06e-04). ETA=0:16:28, max mem: 7.0 GB 
[05/12 21:35:47][INFO] visual_prompt:  219: Epoch 81 / 100: avg data time: 1.75e-03, avg batch time: 0.3028, average train loss: 0.5330
[05/12 21:35:51][INFO] visual_prompt:  324: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1481, average loss: 0.6819
[05/12 21:35:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.33	
[05/12 21:36:06][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.523, 0.1484 s / batch. (data: 3.62e-05)max mem: 6.98685 GB 
[05/12 21:36:18][INFO] visual_prompt:  324: Inference (test):avg data time: 2.81e-05, avg batch time: 0.1477, average loss: 0.6941
[05/12 21:36:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.28	top5: 97.81	
[05/12 21:36:18][INFO] visual_prompt:  165: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[05/12 21:36:48][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4130,	0.3016 s / batch. (data: 9.20e-05). ETA=0:15:38, max mem: 7.0 GB 
[05/12 21:37:09][INFO] visual_prompt:  219: Epoch 82 / 100: avg data time: 2.09e-03, avg batch time: 0.3030, average train loss: 0.5245
[05/12 21:37:12][INFO] visual_prompt:  324: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1478, average loss: 0.6735
[05/12 21:37:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.50	
[05/12 21:37:27][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.597, 0.1483 s / batch. (data: 1.98e-05)max mem: 6.98685 GB 
[05/12 21:37:39][INFO] visual_prompt:  324: Inference (test):avg data time: 2.88e-05, avg batch time: 0.1477, average loss: 0.6855
[05/12 21:37:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.30	top5: 98.03	
[05/12 21:37:39][INFO] visual_prompt:  246: Best epoch 82: best metric: 0.850
[05/12 21:37:39][INFO] visual_prompt:  165: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[05/12 21:38:10][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4799,	0.3015 s / batch. (data: 9.54e-05). ETA=0:14:47, max mem: 7.0 GB 
[05/12 21:38:31][INFO] visual_prompt:  219: Epoch 83 / 100: avg data time: 2.12e-03, avg batch time: 0.3031, average train loss: 0.5214
[05/12 21:38:34][INFO] visual_prompt:  324: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1482, average loss: 0.6723
[05/12 21:38:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.17	
[05/12 21:38:49][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.544, 0.1483 s / batch. (data: 3.79e-05)max mem: 6.98685 GB 
[05/12 21:39:01][INFO] visual_prompt:  324: Inference (test):avg data time: 2.79e-05, avg batch time: 0.1477, average loss: 0.6890
[05/12 21:39:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.47	top5: 97.88	
[05/12 21:39:01][INFO] visual_prompt:  165: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[05/12 21:39:32][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.7769,	0.3014 s / batch. (data: 8.25e-05). ETA=0:13:55, max mem: 7.0 GB 
[05/12 21:39:52][INFO] visual_prompt:  219: Epoch 84 / 100: avg data time: 2.17e-03, avg batch time: 0.3031, average train loss: 0.5142
[05/12 21:39:56][INFO] visual_prompt:  324: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1478, average loss: 0.6707
[05/12 21:39:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.50	
[05/12 21:40:11][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.542, 0.1484 s / batch. (data: 3.79e-05)max mem: 6.98685 GB 
[05/12 21:40:23][INFO] visual_prompt:  324: Inference (test):avg data time: 2.86e-05, avg batch time: 0.1477, average loss: 0.6883
[05/12 21:40:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.36	top5: 98.00	
[05/12 21:40:23][INFO] visual_prompt:  246: Best epoch 84: best metric: 0.853
[05/12 21:40:23][INFO] visual_prompt:  165: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[05/12 21:40:53][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6493,	0.3017 s / batch. (data: 7.75e-05). ETA=0:13:05, max mem: 7.0 GB 
[05/12 21:41:14][INFO] visual_prompt:  219: Epoch 85 / 100: avg data time: 1.98e-03, avg batch time: 0.3029, average train loss: 0.5137
[05/12 21:41:17][INFO] visual_prompt:  324: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1480, average loss: 0.6695
[05/12 21:41:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.17	
[05/12 21:41:32][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.513, 0.1485 s / batch. (data: 3.74e-05)max mem: 6.98685 GB 
[05/12 21:41:44][INFO] visual_prompt:  324: Inference (test):avg data time: 3.47e-05, avg batch time: 0.1477, average loss: 0.6861
[05/12 21:41:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.38	top5: 97.79	
[05/12 21:41:44][INFO] visual_prompt:  165: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[05/12 21:42:15][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5831,	0.3018 s / batch. (data: 8.42e-05). ETA=0:12:14, max mem: 7.0 GB 
[05/12 21:42:36][INFO] visual_prompt:  219: Epoch 86 / 100: avg data time: 2.17e-03, avg batch time: 0.3031, average train loss: 0.5158
[05/12 21:42:39][INFO] visual_prompt:  324: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1479, average loss: 0.6752
[05/12 21:42:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.50	
[05/12 21:42:54][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.516, 0.1486 s / batch. (data: 3.67e-05)max mem: 6.98685 GB 
[05/12 21:43:06][INFO] visual_prompt:  324: Inference (test):avg data time: 2.98e-05, avg batch time: 0.1477, average loss: 0.6881
[05/12 21:43:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.71	top5: 97.81	
[05/12 21:43:06][INFO] visual_prompt:  165: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[05/12 21:43:37][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4305,	0.3016 s / batch. (data: 1.59e-04). ETA=0:11:23, max mem: 7.0 GB 
[05/12 21:43:57][INFO] visual_prompt:  219: Epoch 87 / 100: avg data time: 1.61e-03, avg batch time: 0.3025, average train loss: 0.5142
[05/12 21:44:00][INFO] visual_prompt:  324: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1478, average loss: 0.6781
[05/12 21:44:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.33	
[05/12 21:44:16][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.523, 0.1486 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 21:44:28][INFO] visual_prompt:  324: Inference (test):avg data time: 2.69e-05, avg batch time: 0.1477, average loss: 0.6894
[05/12 21:44:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.66	top5: 97.76	
[05/12 21:44:28][INFO] visual_prompt:  165: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[05/12 21:44:58][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5126,	0.3018 s / batch. (data: 7.61e-05). ETA=0:10:32, max mem: 7.0 GB 
[05/12 21:45:19][INFO] visual_prompt:  219: Epoch 88 / 100: avg data time: 1.91e-03, avg batch time: 0.3028, average train loss: 0.5062
[05/12 21:45:22][INFO] visual_prompt:  324: Inference (val):avg data time: 3.94e-05, avg batch time: 0.1479, average loss: 0.6725
[05/12 21:45:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 98.50	
[05/12 21:45:37][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.559, 0.1483 s / batch. (data: 1.88e-05)max mem: 6.98685 GB 
[05/12 21:45:49][INFO] visual_prompt:  324: Inference (test):avg data time: 3.63e-05, avg batch time: 0.1477, average loss: 0.6837
[05/12 21:45:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.50	top5: 97.86	
[05/12 21:45:49][INFO] visual_prompt:  165: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[05/12 21:46:20][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5287,	0.3017 s / batch. (data: 2.04e-04). ETA=0:09:41, max mem: 7.0 GB 
[05/12 21:46:41][INFO] visual_prompt:  219: Epoch 89 / 100: avg data time: 2.08e-03, avg batch time: 0.3029, average train loss: 0.5127
[05/12 21:46:44][INFO] visual_prompt:  324: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1478, average loss: 0.6736
[05/12 21:46:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.50	
[05/12 21:46:59][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.521, 0.1486 s / batch. (data: 2.05e-05)max mem: 6.98685 GB 
[05/12 21:47:11][INFO] visual_prompt:  324: Inference (test):avg data time: 2.79e-05, avg batch time: 0.1477, average loss: 0.6841
[05/12 21:47:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.85	top5: 97.86	
[05/12 21:47:11][INFO] visual_prompt:  165: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[05/12 21:47:41][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6565,	0.3020 s / batch. (data: 8.13e-05). ETA=0:08:51, max mem: 7.0 GB 
[05/12 21:48:02][INFO] visual_prompt:  219: Epoch 90 / 100: avg data time: 2.09e-03, avg batch time: 0.3031, average train loss: 0.5023
[05/12 21:48:05][INFO] visual_prompt:  324: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1481, average loss: 0.6757
[05/12 21:48:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.33	
[05/12 21:48:21][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.502, 0.1485 s / batch. (data: 2.15e-05)max mem: 6.98685 GB 
[05/12 21:48:33][INFO] visual_prompt:  324: Inference (test):avg data time: 2.91e-05, avg batch time: 0.1477, average loss: 0.6838
[05/12 21:48:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.78	top5: 97.88	
[05/12 21:48:33][INFO] visual_prompt:  165: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[05/12 21:49:03][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.8037,	0.3016 s / batch. (data: 9.66e-05). ETA=0:07:59, max mem: 7.0 GB 
[05/12 21:49:24][INFO] visual_prompt:  219: Epoch 91 / 100: avg data time: 2.02e-03, avg batch time: 0.3030, average train loss: 0.5079
[05/12 21:49:27][INFO] visual_prompt:  324: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1480, average loss: 0.6725
[05/12 21:49:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.50	
[05/12 21:49:42][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.520, 0.1488 s / batch. (data: 3.84e-05)max mem: 6.98685 GB 
[05/12 21:49:54][INFO] visual_prompt:  324: Inference (test):avg data time: 3.26e-05, avg batch time: 0.1477, average loss: 0.6839
[05/12 21:49:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.78	top5: 97.79	
[05/12 21:49:54][INFO] visual_prompt:  165: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[05/12 21:50:25][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.3091,	0.3013 s / batch. (data: 8.49e-05). ETA=0:07:08, max mem: 7.0 GB 
[05/12 21:50:46][INFO] visual_prompt:  219: Epoch 92 / 100: avg data time: 1.66e-03, avg batch time: 0.3025, average train loss: 0.5056
[05/12 21:50:49][INFO] visual_prompt:  324: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1479, average loss: 0.6717
[05/12 21:50:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.50	
[05/12 21:51:04][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.520, 0.1485 s / batch. (data: 2.07e-05)max mem: 6.98685 GB 
[05/12 21:51:16][INFO] visual_prompt:  324: Inference (test):avg data time: 2.39e-05, avg batch time: 0.1477, average loss: 0.6839
[05/12 21:51:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.71	top5: 97.86	
[05/12 21:51:16][INFO] visual_prompt:  165: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[05/12 21:51:46][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6352,	0.3013 s / batch. (data: 8.18e-05). ETA=0:06:17, max mem: 7.0 GB 
[05/12 21:52:07][INFO] visual_prompt:  219: Epoch 93 / 100: avg data time: 2.13e-03, avg batch time: 0.3030, average train loss: 0.4997
[05/12 21:52:10][INFO] visual_prompt:  324: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1478, average loss: 0.6709
[05/12 21:52:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.50	
[05/12 21:52:25][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.528, 0.1485 s / batch. (data: 1.93e-05)max mem: 6.98685 GB 
[05/12 21:52:38][INFO] visual_prompt:  324: Inference (test):avg data time: 3.36e-05, avg batch time: 0.1477, average loss: 0.6832
[05/12 21:52:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.55	top5: 97.83	
[05/12 21:52:38][INFO] visual_prompt:  165: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[05/12 21:53:08][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5890,	0.3016 s / batch. (data: 1.30e-04). ETA=0:05:26, max mem: 7.0 GB 
[05/12 21:53:29][INFO] visual_prompt:  219: Epoch 94 / 100: avg data time: 1.60e-03, avg batch time: 0.3025, average train loss: 0.5030
[05/12 21:53:32][INFO] visual_prompt:  324: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1479, average loss: 0.6699
[05/12 21:53:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.50	
[05/12 21:53:47][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.513, 0.1485 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 21:53:59][INFO] visual_prompt:  324: Inference (test):avg data time: 2.32e-05, avg batch time: 0.1477, average loss: 0.6807
[05/12 21:53:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.71	top5: 97.88	
[05/12 21:53:59][INFO] visual_prompt:  165: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[05/12 21:54:30][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5793,	0.3023 s / batch. (data: 8.01e-05). ETA=0:04:36, max mem: 7.0 GB 
[05/12 21:54:50][INFO] visual_prompt:  219: Epoch 95 / 100: avg data time: 1.65e-03, avg batch time: 0.3026, average train loss: 0.4992
[05/12 21:54:54][INFO] visual_prompt:  324: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1478, average loss: 0.6718
[05/12 21:54:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.50	
[05/12 21:55:09][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.507, 0.1483 s / batch. (data: 2.17e-05)max mem: 6.98685 GB 
[05/12 21:55:21][INFO] visual_prompt:  324: Inference (test):avg data time: 2.32e-05, avg batch time: 0.1477, average loss: 0.6820
[05/12 21:55:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.66	top5: 97.88	
[05/12 21:55:21][INFO] visual_prompt:  165: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[05/12 21:55:51][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4209,	0.3017 s / batch. (data: 8.20e-05). ETA=0:03:44, max mem: 7.0 GB 
[05/12 21:56:12][INFO] visual_prompt:  219: Epoch 96 / 100: avg data time: 2.08e-03, avg batch time: 0.3031, average train loss: 0.4951
[05/12 21:56:15][INFO] visual_prompt:  324: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1479, average loss: 0.6723
[05/12 21:56:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.50	
[05/12 21:56:30][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.511, 0.1484 s / batch. (data: 3.79e-05)max mem: 6.98685 GB 
[05/12 21:56:42][INFO] visual_prompt:  324: Inference (test):avg data time: 2.61e-05, avg batch time: 0.1477, average loss: 0.6818
[05/12 21:56:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.67	top5: 97.89	
[05/12 21:56:42][INFO] visual_prompt:  165: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[05/12 21:57:13][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4347,	0.3012 s / batch. (data: 8.27e-05). ETA=0:02:53, max mem: 7.0 GB 
[05/12 21:57:34][INFO] visual_prompt:  219: Epoch 97 / 100: avg data time: 2.14e-03, avg batch time: 0.3031, average train loss: 0.4980
[05/12 21:57:37][INFO] visual_prompt:  324: Inference (val):avg data time: 5.66e-05, avg batch time: 0.1479, average loss: 0.6711
[05/12 21:57:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.50	
[05/12 21:57:52][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.504, 0.1485 s / batch. (data: 1.88e-05)max mem: 6.98685 GB 
[05/12 21:58:04][INFO] visual_prompt:  324: Inference (test):avg data time: 3.22e-05, avg batch time: 0.1477, average loss: 0.6813
[05/12 21:58:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.73	top5: 97.86	
[05/12 21:58:04][INFO] visual_prompt:  165: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[05/12 21:58:35][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.4996,	0.3018 s / batch. (data: 7.87e-05). ETA=0:02:02, max mem: 7.0 GB 
[05/12 21:58:55][INFO] visual_prompt:  219: Epoch 98 / 100: avg data time: 2.07e-03, avg batch time: 0.3030, average train loss: 0.5002
[05/12 21:58:59][INFO] visual_prompt:  324: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1479, average loss: 0.6709
[05/12 21:58:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.50	
[05/12 21:59:14][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.506, 0.1484 s / batch. (data: 2.19e-05)max mem: 6.98685 GB 
[05/12 21:59:26][INFO] visual_prompt:  324: Inference (test):avg data time: 2.34e-05, avg batch time: 0.1477, average loss: 0.6813
[05/12 21:59:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.71	top5: 97.83	
[05/12 21:59:26][INFO] visual_prompt:  165: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[05/12 21:59:56][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.5200,	0.3016 s / batch. (data: 7.92e-05). ETA=0:01:11, max mem: 7.0 GB 
[05/12 22:00:17][INFO] visual_prompt:  219: Epoch 99 / 100: avg data time: 2.14e-03, avg batch time: 0.3031, average train loss: 0.4986
[05/12 22:00:20][INFO] visual_prompt:  324: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1479, average loss: 0.6710
[05/12 22:00:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.50	
[05/12 22:00:35][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.503, 0.1484 s / batch. (data: 2.00e-05)max mem: 6.98685 GB 
[05/12 22:00:48][INFO] visual_prompt:  324: Inference (test):avg data time: 3.20e-05, avg batch time: 0.1478, average loss: 0.6813
[05/12 22:00:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.73	top5: 97.83	
[05/12 22:00:48][INFO] visual_prompt:  165: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[05/12 22:01:18][INFO] visual_prompt:  213: 	Training 100/169. train loss: 0.6563,	0.3015 s / batch. (data: 7.82e-05). ETA=0:00:20, max mem: 7.0 GB 
[05/12 22:01:39][INFO] visual_prompt:  219: Epoch 100 / 100: avg data time: 1.81e-03, avg batch time: 0.3028, average train loss: 0.5017
[05/12 22:01:42][INFO] visual_prompt:  324: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1481, average loss: 0.6709
[05/12 22:01:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.50	
[05/12 22:01:57][INFO] visual_prompt:  314: 	Test 100/182. loss: 0.504, 0.1483 s / batch. (data: 3.79e-05)max mem: 6.98685 GB 
[05/12 22:02:09][INFO] visual_prompt:  324: Inference (test):avg data time: 3.37e-05, avg batch time: 0.1478, average loss: 0.6814
[05/12 22:02:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.73	top5: 97.83	
